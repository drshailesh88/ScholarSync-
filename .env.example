# Database (PostgreSQL 16 with pgvector)
DATABASE_URL=postgresql://user:password@localhost:5432/scholarsync

# Authentication (Clerk)
NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=pk_test_...
CLERK_SECRET_KEY=sk_test_...
CLERK_WEBHOOK_SECRET=whsec_...

# ── AI Provider ─────────────────────────────────────────────────────
# Set AI_PROVIDER to choose your LLM backend:
#   "zhipu"     → Z.AI GLM-5  (default, cost-effective for development)
#   "anthropic" → Anthropic Claude
AI_PROVIDER=zhipu

# Z.AI (GLM-5) — required when AI_PROVIDER=zhipu
ZHIPU_API_KEY=your-zhipu-api-key

# Anthropic Claude — required when AI_PROVIDER=anthropic
# ANTHROPIC_API_KEY=sk-ant-...

# Embeddings (OpenAI)
OPENAI_API_KEY=sk-...

# Optional: Cohere API key for search result reranking
COHERE_API_KEY=

# PubMed API keys (comma-separated for rotation — get free keys at https://ncbiinsights.ncbi.nlm.nih.gov/2017/11/02/new-api-keys-for-the-e-utilities/)
# Multiple keys enable round-robin rotation to avoid rate limits at scale.
# Falls back to PUBMED_API_KEY (singular) for backward compatibility.
PUBMED_API_KEYS=

# Optional: Semantic Scholar API key for higher rate limits
SEMANTIC_SCHOLAR_API_KEY=

# PDF Storage (local dev — will be GCS in production)
PDF_STORAGE_PATH=

# Docling PDF Parsing Service (Python microservice)
# Start locally: cd services/docling && pip install -r requirements.txt && uvicorn app:app --port 8001
DOCLING_SERVICE_URL=http://localhost:8001

# Dev mode (set DEV_USER_ID to bypass auth in development)
# DEV_USER_ID=dev_user_001
