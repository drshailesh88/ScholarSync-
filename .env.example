# Database (PostgreSQL 16 with pgvector)
DATABASE_URL=postgresql://user:password@localhost:5432/scholarsync

# Authentication (Clerk)
NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=pk_test_...
CLERK_SECRET_KEY=sk_test_...
CLERK_WEBHOOK_SECRET=whsec_...

# ── AI Provider ─────────────────────────────────────────────────────
# Set AI_PROVIDER to choose your LLM backend:
#   "anthropic" → Anthropic Claude (default, recommended for medical/academic)
#   "zhipu"     → Z.AI GLM-5  (alternative)
AI_PROVIDER=anthropic

# Anthropic Claude — required when AI_PROVIDER=anthropic
ANTHROPIC_API_KEY=sk-ant-...

# Z.AI (GLM-5) — required when AI_PROVIDER=zhipu
# ZHIPU_API_KEY=your-zhipu-api-key

# Embeddings (OpenAI)
OPENAI_API_KEY=sk-...

# Optional: Cohere API key for search result reranking
COHERE_API_KEY=

# Optional: Semantic Scholar API key for higher rate limits
SEMANTIC_SCHOLAR_API_KEY=

# PDF Storage (local dev — will be GCS in production)
PDF_STORAGE_PATH=

# Docling PDF Parsing Service (Python microservice)
# Start locally: cd services/docling && pip install -r requirements.txt && uvicorn app:app --port 8001
DOCLING_SERVICE_URL=http://localhost:8001

# ── Rate Limiting (Upstash Redis — optional, uses in-memory fallback) ──
# UPSTASH_REDIS_REST_URL=https://your-instance.upstash.io
# UPSTASH_REDIS_REST_TOKEN=your-token

# ── CORS (optional, comma-separated allowed origins) ──
# CORS_ALLOWED_ORIGINS=https://yourdomain.com,https://app.yourdomain.com

# Dev mode (set DEV_USER_ID to bypass auth in development)
# DEV_USER_ID=dev_user_001
